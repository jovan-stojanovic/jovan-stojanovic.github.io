<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en, fr"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://jovan-stojanovic.github.io//feed.xml" rel="self" type="application/atom+xml"/><link href="https://jovan-stojanovic.github.io//" rel="alternate" type="text/html" hreflang="en, fr"/><updated>2023-10-26T08:40:19+00:00</updated><id>https://jovan-stojanovic.github.io//feed.xml</id><title type="html">blank</title><subtitle>Jovan StojanoviÄ‡&apos;s personal website. </subtitle><entry><title type="html">I am a PhD Student</title><link href="https://jovan-stojanovic.github.io//blog/2023/phd-post/" rel="alternate" type="text/html" title="I am a PhD Student"/><published>2023-10-03T16:40:16+00:00</published><updated>2023-10-03T16:40:16+00:00</updated><id>https://jovan-stojanovic.github.io//blog/2023/phd-post</id><content type="html" xml:base="https://jovan-stojanovic.github.io//blog/2023/phd-post/"><![CDATA[<p>I am happy to announce that I will be a PhD Candidate at Inria and UniversitÃ© Paris-Saclay for the next three years.</p> <h4 id="i-will-be-working-on">I will be working on:</h4> <ul> <li>networks</li> <li>econometrics</li> <li>machine learning</li> </ul> <p>I will be posting news on this website.</p> <blockquote> The master-economist must possess a rare combination of gifts. He must be mathematician, historian, statesman, philosopher â€” in some degree. He must understand symbols and speak in words. He must contemplate the particular, in terms of the general, and touch abstract and concrete in the same flight of thought. He must study the present in the light of the past for the purposes of the future. No part of man's nature or his institutions must be entirely outside his regard. He must be purposeful and disinterested in a simultaneous mood, as aloof and incorruptible as an artist, yet sometimes as near to earth as a politician. â€”John Maynard Keynes </blockquote>]]></content><author><name></name></author><category term="sample-posts"/><category term="PhD"/><category term="research"/><summary type="html"><![CDATA[I am a PhD Candidate at Inria and UniversitÃ© Paris-Saclay for the next three years.]]></summary></entry><entry><title type="html">Using skrub</title><link href="https://jovan-stojanovic.github.io//blog/2023/jupytercon/" rel="alternate" type="text/html" title="Using skrub"/><published>2023-05-11T15:09:00+00:00</published><updated>2023-05-11T15:09:00+00:00</updated><id>https://jovan-stojanovic.github.io//blog/2023/jupytercon</id><content type="html" xml:base="https://jovan-stojanovic.github.io//blog/2023/jupytercon/"><![CDATA[<p>JupyterCon 2023 presentation tutorial: Machine learning with dirty tables: encoding, joining and deduplicating</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">python
</span><span class="c1"># %% [markdown]
# # Installing *dirty_cat* from source
</span>
<span class="c1"># %%
# From source:
# !git clone https://github.com/dirty-cat/dirty_cat
# !pip install ./dirty_cat
</span>
<span class="c1"># From PyPi:
# !pip install dirty_cat
</span>
<span class="c1"># %%
</span><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="kn">import</span> <span class="n">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">"</span><span class="s">ignore</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># %% [markdown]
# # Using the library with an example: employee salaries
# 
# We will load a dataset which contains information on more than 9000 employees from Montgomery County, Maryland:
</span>
<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">dirty_cat.datasets</span> <span class="kn">import</span> <span class="n">fetch_employee_salaries</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="nf">fetch_employee_salaries</span><span class="p">()</span>
<span class="c1"># Aliases
</span><span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">X</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">y</span>

<span class="c1"># Pre-processing steps
</span><span class="n">X</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">"</span><span class="s">underfilled_job_title</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">department</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">division</span><span class="sh">"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="sh">"</span><span class="s">columns</span><span class="sh">"</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">X</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>

<span class="c1"># %% [markdown]
# Our goal will be to predict the annual salary using this information.
</span>
<span class="c1"># %% [markdown]
# ## **1. Encoding dirty categorical variables**
</span>
<span class="c1"># %% [markdown]
# ![Encoding](photos/encoding.png)
</span>
<span class="c1"># %% [markdown]
# ## A problem of similarity
</span>
<span class="c1"># %%
# Pick a sample with similar employee position titles
</span><span class="n">sample</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">contains</span><span class="p">(</span><span class="sh">"</span><span class="s">Fire|Social</span><span class="sh">"</span><span class="p">)].</span><span class="nf">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">50</span><span class="p">).</span><span class="nf">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">sample</span><span class="p">[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">]</span>

<span class="c1"># %% [markdown]
# Let's see how `OneHotEncoder` behaves with those
</span>
<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="n">ohe</span> <span class="o">=</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">sparse_output</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">s_enc_ohe</span> <span class="o">=</span> <span class="n">ohe</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">sample</span><span class="p">[[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">]])</span>

<span class="c1"># Make it look nice in Jupyter by wrapping it in a DataFrame
</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">s_enc_ohe</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">ohe</span><span class="p">.</span><span class="n">categories_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">])</span>

<span class="c1"># %% [markdown]
# - OneHot gives equidistant encodings!
# - Dimensionality explodes
# - Rare categories (maybe unknown to test set)
</span>
<span class="c1"># %% [markdown]
# # Similarity encoding: easy to understand
</span>
<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">dirty_cat</span> <span class="kn">import</span> <span class="n">SimilarityEncoder</span>

<span class="n">sim</span> <span class="o">=</span> <span class="nc">SimilarityEncoder</span><span class="p">()</span>
<span class="n">s_enc_sim</span> <span class="o">=</span> <span class="n">sim</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">sample</span><span class="p">[[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">]])</span>

<span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">s_enc_sim</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">sim</span><span class="p">.</span><span class="n">categories_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">])</span>

<span class="c1"># %% [markdown]
# The similarity encoding on the other hand encodes the similarities between each category.
</span>
<span class="c1"># %% [markdown]
# How? Using the **n-gram similarity**:
# 
# ![Encoding](photos/ngram.png)
# 
# - $Similarity=\frac{\text{# n-grams in common}}{\text{# n-grams in total}}$
# - Based on substring comparison.
# - Faster than Levenshtein or Jaro-Winkler with better results.
</span>
<span class="c1"># %% [markdown]
# In conclusion:
# 
# The `SimilarityEncoder` is extending the OHE logic based on the n-gram morphological similarity.
</span>
<span class="c1"># %% [markdown]
# # Gamma-Poisson encoding: by topics and interpretable
</span>
<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">dirty_cat</span> <span class="kn">import</span> <span class="n">GapEncoder</span>

<span class="n">gap</span> <span class="o">=</span> <span class="nc">GapEncoder</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pos_enc</span> <span class="o">=</span> <span class="n">gap</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">[[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">]])</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Shape of encoded vectors: </span><span class="si">{</span><span class="n">pos_enc</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># %%
# We can print the labels that were infered for each topic
</span><span class="n">topic_labels</span> <span class="o">=</span> <span class="n">gap</span><span class="p">.</span><span class="nf">get_feature_names_out</span><span class="p">(</span><span class="n">n_labels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">topic_labels</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Topic nÂ°</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">labels</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># %%
</span><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">encoded_labels</span> <span class="o">=</span> <span class="n">gap</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">sample</span><span class="p">[[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">]])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">encoded_labels</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Latent topics</span><span class="sh">"</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">topic_labels</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="sh">"</span><span class="s">right</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Data entries</span><span class="sh">"</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">sample</span><span class="p">[[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">]].</span><span class="nf">to_numpy</span><span class="p">().</span><span class="nf">flatten</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">().</span><span class="nf">set_label</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Topic activations</span><span class="sh">"</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># %% [markdown]
# In conclusion:
# 
# **The `GapEncoder` extracts latent topics from categories and uses them to evaluate their similarity.**
</span>
<span class="c1"># %% [markdown]
# # Min-hash encoding: very scalable
</span>
<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">dirty_cat</span> <span class="kn">import</span> <span class="n">MinHashEncoder</span>

<span class="n">minhash</span> <span class="o">=</span> <span class="nc">MinHashEncoder</span><span class="p">()</span>
<span class="n">minhash_enc</span> <span class="o">=</span> <span class="n">minhash</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">sample</span><span class="p">[[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">]])</span>

<span class="nf">print</span><span class="p">(</span><span class="n">minhash_enc</span><span class="p">)</span>

<span class="c1"># %% [markdown]
# The resulting encoded category will be the intersection of its components. 
# 
# ![MinHashEncoder](photos/minhash2.png)
# 
# Source: *P.Cerda, G.Varoquaux. Encoding high-cardinality string categorical variables (2019)*
</span>
<span class="c1"># %% [markdown]
# **CCL: The `MinHashEncoder` is an extremely efficient encoding method based on the minhash function.**
</span>
<span class="c1"># %% [markdown]
# # Comparing encoding methods
# 
# We'll run a pipeline with each encoding method we just saw, and a learner, here a `HistGradientBoostingRegressor`.
</span>
<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="n">sklearn.compose</span> <span class="kn">import</span> <span class="n">make_column_transformer</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">HistGradientBoostingRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ShuffleSplit</span>

<span class="n">all_scores</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>
<span class="n">all_times</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>

<span class="n">ohe</span> <span class="o">=</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="sh">"</span><span class="s">ignore</span><span class="sh">"</span><span class="p">,</span> <span class="n">sparse_output</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span>
    <span class="n">ohe</span><span class="p">,</span>
    <span class="nc">SimilarityEncoder</span><span class="p">(),</span>
    <span class="nc">GapEncoder</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">50</span><span class="p">),</span>
    <span class="nc">MinHashEncoder</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span>
<span class="p">]:</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">method</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="nf">make_column_transformer</span><span class="p">(</span>
        <span class="p">(</span><span class="n">ohe</span><span class="p">,</span> <span class="p">[</span><span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">department_name</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">assignment_category</span><span class="sh">"</span><span class="p">]),</span>
        <span class="p">(</span><span class="sh">"</span><span class="s">passthrough</span><span class="sh">"</span><span class="p">,</span> <span class="p">[</span><span class="sh">"</span><span class="s">year_first_hired</span><span class="sh">"</span><span class="p">]),</span>
        <span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="p">[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">]),</span>
        <span class="n">remainder</span><span class="o">=</span><span class="sh">"</span><span class="s">drop</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">pipeline</span> <span class="o">=</span> <span class="nf">make_pipeline</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="nc">HistGradientBoostingRegressor</span><span class="p">())</span>
    <span class="n">results</span> <span class="o">=</span> <span class="nf">cross_validate</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="nc">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="sh">"</span><span class="s">test_score</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">times</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="sh">"</span><span class="s">fit_time</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">all_times</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">times</span>
    <span class="n">all_scores</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores</span>

<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">seaborn</span> <span class="kn">import</span> <span class="n">boxplot</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">ax</span> <span class="o">=</span> <span class="nf">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">all_scores</span><span class="p">),</span> <span class="n">orient</span><span class="o">=</span><span class="sh">"</span><span class="s">h</span><span class="sh">"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Prediction score (R2)</span><span class="sh">"</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="p">[</span><span class="n">t</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">ax1</span><span class="p">.</span><span class="nf">get_yticklabels</span><span class="p">()]</span>


<span class="nf">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">all_times</span><span class="p">),</span> <span class="n">orient</span><span class="o">=</span><span class="sh">"</span><span class="s">h</span><span class="sh">"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Computation time (s)</span><span class="sh">"</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="p">[</span><span class="n">t</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">ax2</span><span class="p">.</span><span class="nf">get_yticklabels</span><span class="p">()]</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>

<span class="c1"># %% [markdown]
# # Automating the boring stuff with the `TableVectorizer`
# 
# Typically, when we want to assemble different encoders for our dataset, we'll use the `ColumnTransformer`:
</span>
<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">dirty_cat</span> <span class="kn">import</span> <span class="n">TableVectorizer</span>

<span class="n">pipeline_tv</span> <span class="o">=</span> <span class="nf">make_pipeline</span><span class="p">(</span>
    <span class="nc">TableVectorizer</span><span class="p">(),</span>
    <span class="nc">HistGradientBoostingRegressor</span><span class="p">(),</span>
<span class="p">)</span>

<span class="c1"># %%
</span><span class="n">pipeline_tv</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">TableVectorizer pipeline score:</span><span class="sh">"</span><span class="p">,</span> <span class="n">pipeline_tv</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>

<span class="c1"># %% [markdown]
# What does it do? Let's see:
</span>
<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>  <span class="c1"># pretty print
</span><span class="nf">pprint</span><span class="p">(</span><span class="n">pipeline_tv</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">transformers_</span><span class="p">)</span>

<span class="c1"># %% [markdown]
# It recognized and used the datetimes (`date_first_hired`) automatically, and encoded it with `dirty_cat.DatetimeEncoder()` ðŸ˜‰
</span>
<span class="c1"># %% [markdown]
# The `TableVectorizer` is simpler to use than `ColumnTransformer`, and works out of the box for most dirty tables.
# It can be easily customized and supports numerical, categorical and datetime features.
</span>
<span class="c1"># %% [markdown]
# Conclusion:
# - The `TableVectorizer` is best to use as it's automatically taking care of the encoding choices.
</span>
<span class="c1"># %% [markdown]
# # **2. Fuzzy joining tables with dirty data**
</span>
<span class="c1"># %% [markdown]
# ![fj](photos/fj.png)
</span>
<span class="c1"># %% [markdown]
# ## Better `pandas.merge`: `fuzzy_join`
</span>
<span class="c1"># %%
</span><span class="n">baltimore</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">https://data.baltimorecity.gov/datasets/baltimore::baltimore-city-employee-salaries.csv</span><span class="sh">"</span><span class="p">)[[</span><span class="sh">"</span><span class="s">agencyName</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">jobClass</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">annualSalary</span><span class="sh">"</span><span class="p">]]</span>
<span class="n">baltimore</span> <span class="o">=</span> <span class="n">baltimore</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">agencyName</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">jobClass</span><span class="sh">"</span><span class="p">]).</span><span class="nf">mean</span><span class="p">().</span><span class="nf">reset_index</span><span class="p">()</span>
<span class="n">baltimore</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span>

<span class="c1"># %%
</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">baltimore</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="sh">'</span><span class="s">employee_position_title</span><span class="sh">'</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="sh">'</span><span class="s">jobClass</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">dirty_cat</span> <span class="kn">import</span> <span class="n">fuzzy_join</span>

<span class="n">X2</span> <span class="o">=</span> <span class="nf">fuzzy_join</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">baltimore</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="sh">'</span><span class="s">employee_position_title</span><span class="sh">'</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="sh">'</span><span class="s">jobClass</span><span class="sh">'</span><span class="p">,</span> <span class="n">return_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X2</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>

<span class="c1"># %%
</span><span class="n">X2</span><span class="p">[[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">jobClass</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">matching_score</span><span class="sh">"</span><span class="p">]].</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">"</span><span class="s">matching_score</span><span class="sh">"</span><span class="p">).</span><span class="nf">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># %%
</span><span class="n">X2_bis</span> <span class="o">=</span> <span class="nf">fuzzy_join</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">baltimore</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="sh">'</span><span class="s">employee_position_title</span><span class="sh">'</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="sh">'</span><span class="s">jobClass</span><span class="sh">'</span><span class="p">,</span> <span class="n">match_score</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">X2_bis</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>

<span class="c1"># %% [markdown]
# # Automating the boring stuff: multiple `fuzzy_join`'s with `FeatureAugmenter`
</span>
<span class="c1"># %% [markdown]
# Case of a datalake: often the case in real production settings (big companies or public institutions).
# 
# You need to join multiple tables on the initial one to add information (feature augmentation).
</span>
<span class="c1"># %%
</span><span class="n">population</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">https://opendata.maryland.gov/api/views/sk8g-4e43/rows.csv?accessType=DOWNLOAD</span><span class="sh">"</span><span class="p">)</span>
<span class="n">population</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span>

<span class="c1"># %%
</span><span class="n">minimum_wage</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">https://raw.githubusercontent.com/Lislejoem/Minimum-Wage-by-State-1968-to-2020/master/Minimum%20Wage%20Data.csv</span><span class="sh">"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">'</span><span class="s">latin</span><span class="sh">'</span><span class="p">)</span>
<span class="n">minimum_wage</span> <span class="o">=</span> <span class="n">minimum_wage</span><span class="p">[</span><span class="n">minimum_wage</span><span class="p">[</span><span class="sh">"</span><span class="s">State</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">Maryland</span><span class="sh">'</span><span class="p">][[</span><span class="sh">"</span><span class="s">State.Minimum.Wage.2020.Dollars</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Year</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">State</span><span class="sh">"</span><span class="p">]]</span>
<span class="n">minimum_wage</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>

<span class="c1"># %% [markdown]
# Repeating `fuzzy_join`'s over and over for each new table tables is painful:
</span>
<span class="c1"># %% [markdown]
# We now have a class we can introduce in our ML pipeline!
</span>
<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">dirty_cat</span> <span class="kn">import</span> <span class="n">FeatureAugmenter</span>

<span class="n">faugmenter</span> <span class="o">=</span> <span class="nc">FeatureAugmenter</span><span class="p">(</span><span class="n">tables</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="sh">"</span><span class="s">Year</span><span class="sh">"</span><span class="p">),</span>
        <span class="p">(</span><span class="n">minimum_wage</span><span class="p">,</span> <span class="sh">"</span><span class="s">Year</span><span class="sh">"</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">main_key</span><span class="o">=</span><span class="sh">"</span><span class="s">year_first_hired</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># %%
</span><span class="n">pipeline_fj</span> <span class="o">=</span> <span class="nf">make_pipeline</span><span class="p">(</span>
    <span class="n">faugmenter</span><span class="p">,</span>
    <span class="nc">TableVectorizer</span><span class="p">(),</span>
    <span class="nc">HistGradientBoostingRegressor</span><span class="p">(),</span>
<span class="p">)</span>

<span class="n">pipeline_fj</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X2_train</span><span class="p">,</span> <span class="n">y2_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">TableVectorizer with fuzzy_join pipeline score:</span><span class="sh">"</span><span class="p">,</span> <span class="n">pipeline_fj</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X2_test</span><span class="p">,</span> <span class="n">y2_test</span><span class="p">))</span>

<span class="c1"># %% [markdown]
# Conclusion:
# - The `fuzzy_join` is a function that allows you to join two tables on imprecise correspondences. It is based on the n-gram morphological similarity of categories.
# - The `FeatureAugmenter` can do this on multiple tables on a common join key. scikit-learn compatible, can be used in a pipeline.
</span>
<span class="c1"># %% [markdown]
# # **3. Deduplicating dirty categorical variables**
</span>
<span class="c1"># %% [markdown]
# ![deduplicating](photos/deduplicated.png)
</span>
<span class="c1"># %% [markdown]
# ## Clean typos from your data with deduplication
</span>
<span class="c1"># %%
</span><span class="kn">from</span> <span class="n">dirty_cat</span> <span class="kn">import</span> <span class="n">deduplicate</span>
<span class="nf">deduplicate</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="sh">"</span><span class="s">employee_position_title</span><span class="sh">"</span><span class="p">])</span>

<span class="c1"># %% [markdown]
# Good for getting back into the OHE use case. Beware of potential losses of information.</span>
<span class="p">```</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="sample-posts"/><category term="code"/><summary type="html"><![CDATA[JupyterCon 2023 tutorial]]></summary></entry><entry><title type="html">Happy to join Inria!</title><link href="https://jovan-stojanovic.github.io//blog/2022/images/" rel="alternate" type="text/html" title="Happy to join Inria!"/><published>2022-03-15T21:01:00+00:00</published><updated>2022-03-15T21:01:00+00:00</updated><id>https://jovan-stojanovic.github.io//blog/2022/images</id><content type="html" xml:base="https://jovan-stojanovic.github.io//blog/2022/images/"><![CDATA[<p>I am very happy to announce that I will be joining Inria as a software engineer and data scientist working on dirty data.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/inria-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/inria-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/inria-1400.webp"/> <img src="/assets/img/inria.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/soda-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/soda-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/soda-1400.webp"/> <img src="/assets/img/soda.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> I will be joining Soda team, doing research at the intersection between machine-learning, databases, and quantitative social sciences. </div>]]></content><author><name></name></author><category term="sample-posts"/><category term="software"/><summary type="html"><![CDATA[I will join Inria as a software engineer.]]></summary></entry></feed>